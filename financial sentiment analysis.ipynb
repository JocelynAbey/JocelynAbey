{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VFBjNjUwJcR1i878f6Cp0hOmsNWC3GW6",
      "authorship_tag": "ABX9TyMBEkkoIP7iMZv+05qqUfOs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JocelynAbey/JocelynAbey/blob/main/financial%20sentiment%20analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet, sentiwordnet as swn\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "yo3lki5XQK0P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure necessary downloads (run these once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVzoE0bKQamQ",
        "outputId": "0fed9b20-6c36-4859-ec70-d1ef61ce697b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/NLPAssignment/FinancialSentimentAnalysis (1).csv\"  # Change the path as needed\n",
        "fsa = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Display info and description of dataframe\n",
        "print(fsa.info())\n",
        "print(fsa.describe())\n",
        "\n",
        "# Step 2: Preprocessing\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuations, numbers, and special characters\n",
        "    words = word_tokenize(text)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # Lemmatization & stopwords removal\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Apply preprocessing\n",
        "fsa[\"Processed_Sentence\"] = fsa[\"Sentence\"].astype(str).apply(preprocess_text)\n",
        "\n",
        "# Step 3: SentiWordNet Sentiment Score Calculation\n",
        "def get_sentiwordnet_score(text):\n",
        "    words = word_tokenize(text)\n",
        "    score = 0\n",
        "    count = 0\n",
        "\n",
        "    for word in words:\n",
        "        synsets = wordnet.synsets(word)\n",
        "        if synsets:\n",
        "            synset = synsets[0]  # Use first synset\n",
        "            senti_synset = swn.senti_synset(synset.name())\n",
        "            score += senti_synset.pos_score() - senti_synset.neg_score()\n",
        "            count += 1\n",
        "\n",
        "    return score / count if count > 0 else 0\n",
        "\n",
        "# Apply sentiment scoring\n",
        "fsa[\"Sentiment_Score\"] = fsa[\"Processed_Sentence\"].apply(get_sentiwordnet_score)\n",
        "\n",
        "# Display results\n",
        "print(fsa[[\"Sentence\", \"Processed_Sentence\", \"Sentiment_Score\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8leIGemSQgME",
        "outputId": "4bfaa117-f57f-48a7-9b2b-9489b2e61653"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5842 entries, 0 to 5841\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Sentence   5842 non-null   object\n",
            " 1   Sentiment  5842 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 91.4+ KB\n",
            "None\n",
            "                                                 Sentence Sentiment\n",
            "count                                                5842      5842\n",
            "unique                                               5322         3\n",
            "top     Managing Director 's comments : `` Net sales f...   neutral\n",
            "freq                                                    2      3130\n",
            "                                            Sentence  \\\n",
            "0  The GeoSolutions technology will leverage Bene...   \n",
            "1  $ESI on lows, down $1.50 to $2.50 BK a real po...   \n",
            "2  For the last quarter of 2010 , Componenta 's n...   \n",
            "3  According to the Finnish-Russian Chamber of Co...   \n",
            "4  The Swedish buyout firm has sold its remaining...   \n",
            "\n",
            "                                  Processed_Sentence  Sentiment_Score  \n",
            "0  geosolutions technology leverage benefon gps s...         0.032895  \n",
            "1                        esi low bk real possibility         0.000000  \n",
            "2  last quarter componenta net sale doubled eurm ...        -0.010417  \n",
            "3  according finnishrussian chamber commerce majo...        -0.013889  \n",
            "4  swedish buyout firm sold remaining percent sta...         0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Ensure necessary downloads (run these once)\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Sample words from dataset for analysis\n",
        "sample_words = [\"profit\", \"loss\", \"growth\", \"investment\"]\n",
        "\n",
        "# a. Synsets\n",
        "for word in sample_words:\n",
        "    synsets = wordnet.synsets(word)\n",
        "    print(f\"Synsets for '{word}': {[syn.name() for syn in synsets]}\")\n",
        "\n",
        "# b. Synonyms and Antonyms\n",
        "for word in sample_words:\n",
        "    synonyms = set()\n",
        "    antonyms = set()\n",
        "\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "            if lemma.antonyms():\n",
        "                antonyms.add(lemma.antonyms()[0].name())\n",
        "\n",
        "    print(f\"Synonyms for '{word}': {synonyms}\")\n",
        "    print(f\"Antonyms for '{word}': {antonyms}\")\n",
        "\n",
        "# c. Hyponym and Hypernym\n",
        "for word in sample_words:\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if synsets:\n",
        "        hyponyms = synsets[0].hyponyms()\n",
        "        hypernyms = synsets[0].hypernyms()\n",
        "        print(f\"Hyponyms for '{word}': {[hypo.lemma_names() for hypo in hyponyms]}\")\n",
        "        print(f\"Hypernyms for '{word}': {[hyper.lemma_names() for hyper in hypernyms]}\")\n",
        "\n",
        "# d. WordNet Path Similarity\n",
        "word1, word2 = \"profit\", \"loss\"\n",
        "syn1 = wordnet.synsets(word1)[0]  # First synset\n",
        "syn2 = wordnet.synsets(word2)[0]  # First synset\n",
        "similarity = syn1.path_similarity(syn2)\n",
        "print(f\"Path similarity between '{word1}' and '{word2}': {similarity}\")\n",
        "\n",
        "# e. Word Sense Disambiguation using Lesk Algorithm\n",
        "from nltk.wsd import lesk\n",
        "\n",
        "sentence = \"The company made a huge profit last quarter.\"\n",
        "disambiguated_sense = lesk(sentence.split(), \"profit\")\n",
        "print(f\"Disambiguated sense for 'profit': {disambiguated_sense}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf8EJLFmRs_q",
        "outputId": "094e726d-1ab5-4865-ff53-cb924dad1886"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synsets for 'profit': ['net_income.n.01', 'profit.n.02', 'profit.v.01', 'profit.v.02']\n",
            "Synsets for 'loss': ['loss.n.01', 'loss.n.02', 'loss.n.03', 'loss.n.04', 'loss.n.05', 'loss.n.06', 'personnel_casualty.n.01', 'passing.n.02']\n",
            "Synsets for 'growth': ['growth.n.01', 'growth.n.02', 'increase.n.03', 'growth.n.04', 'emergence.n.01', 'growth.n.06', 'growth.n.07']\n",
            "Synsets for 'investment': ['investing.n.01', 'investment.n.02', 'investment.n.03', 'investment.n.04', 'investment.n.05', 'investment.n.06']\n",
            "Synonyms for 'profit': {'earnings', 'net_income', 'profits', 'turn_a_profit', 'lucre', 'benefit', 'net_profit', 'net', 'profit', 'gain'}\n",
            "Antonyms for 'profit': {'lose'}\n",
            "Synonyms for 'loss': {'deprivation', 'expiration', 'red', 'departure', 'personnel_casualty', 'red_ink', 'loss', 'release', 'going', 'exit', 'passing'}\n",
            "Antonyms for 'loss': {'gain'}\n",
            "Synonyms for 'growth': {'maturation', 'development', 'outgrowth', 'growth', 'ontogeny', 'growing', 'emergence', 'increment', 'ontogenesis', 'increase'}\n",
            "Antonyms for 'growth': {'decrease', 'nondevelopment', 'decrement'}\n",
            "Synonyms for 'investment': {'investment', 'investing', 'investiture', 'investment_funds'}\n",
            "Antonyms for 'investment': set()\n",
            "Hyponyms for 'profit': [['filthy_lucre'], ['markup'], ['gross_profit', 'gross_profit_margin', 'margin'], ['dividend'], ['windfall_profit'], ['accumulation'], ['killing', 'cleanup'], ['fast_buck', 'quick_buck'], ['earning_per_share']]\n",
            "Hypernyms for 'profit': [['income']]\n",
            "Hyponyms for 'loss': [['forfeit', 'forfeiture'], ['sacrifice'], ['wastage'], ['financial_loss']]\n",
            "Hypernyms for 'loss': [['transferred_property', 'transferred_possession']]\n",
            "Hyponyms for 'growth': [['teratogenesis'], ['psychogenesis'], ['foliation', 'leafing'], ['fructification'], ['neurogenesis'], ['rooting'], ['masculinization', 'masculinisation', 'virilization', 'virilisation'], ['suppression'], ['psychogenesis'], ['auxesis'], ['gametogenesis'], ['germination', 'sprouting'], ['palingenesis', 'recapitulation'], ['infructescence'], ['intussusception'], ['apposition'], ['cytogenesis', 'cytogeny'], ['cenogenesis', 'kenogenesis', 'caenogenesis', 'cainogenesis', 'kainogenesis'], ['myelinization', 'myelinisation'], ['angiogenesis'], ['amelogenesis'], ['cultivation'], ['teething', 'dentition', 'odontiasis'], ['life_cycle'], ['culture'], ['morphogenesis'], ['blossoming', 'flowering', 'florescence', 'inflorescence', 'anthesis', 'efflorescence'], ['proliferation'], ['cohesion'], ['psychomotor_development'], ['vegetation'], ['psychosexual_development'], ['juvenescence'], ['habit']]\n",
            "Hypernyms for 'growth': [['organic_process', 'biological_process']]\n",
            "Hyponyms for 'investment': [['arbitrage'], ['leverage', 'leveraging'], ['foreign_direct_investment']]\n",
            "Hypernyms for 'investment': [['finance']]\n",
            "Path similarity between 'profit' and 'loss': 0.1111111111111111\n",
            "Disambiguated sense for 'profit': Synset('profit.v.02')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    }
  ]
}