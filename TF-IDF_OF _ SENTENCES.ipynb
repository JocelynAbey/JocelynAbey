{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8CPKWNW6MTpxkU96KvLj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JocelynAbey/JocelynAbey/blob/main/TF-IDF_OF%20_%20SENTENCES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fjJGOavPulc",
        "outputId": "1ad9d143-3c0b-4147-ea0d-92b646edb4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro06HGMCGcc3",
        "outputId": "1952db0c-18b3-4dc1-8c7e-3d0075766d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text:\n",
            "Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems.\n",
            "These processes include learning, reasoning, and self-correction. AI has been widely applied in various industries such as\n",
            "healthcare, finance, robotics, and customer service. In healthcare, AI is used for diagnosing diseases, analyzing medical images,\n",
            "and even developing personalized treatment plans. In finance, AI algorithms help in fraud detection, algorithmic trading, and risk management.\n",
            "As AI technology advances, there are concerns regarding its ethical implications, particularly with respect to privacy, job displacement,\n",
            "and decision-making processes. Despite these challenges, AI continues to show significant potential in transforming industries and improving the quality of life.\n",
            "\n",
            "Summary:\n",
            "Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. In healthcare, AI is used for diagnosing diseases, analyzing medical images,\n",
            "and even developing personalized treatment plans. As AI technology advances, there are concerns regarding its ethical implications, particularly with respect to privacy, job displacement,\n",
            "and decision-making processes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems.\n",
        "These processes include learning, reasoning, and self-correction. AI has been widely applied in various industries such as\n",
        "healthcare, finance, robotics, and customer service. In healthcare, AI is used for diagnosing diseases, analyzing medical images,\n",
        "and even developing personalized treatment plans. In finance, AI algorithms help in fraud detection, algorithmic trading, and risk management.\n",
        "As AI technology advances, there are concerns regarding its ethical implications, particularly with respect to privacy, job displacement,\n",
        "and decision-making processes. Despite these challenges, AI continues to show significant potential in transforming industries and improving the quality of life.\n",
        "\"\"\"\n",
        "# Step 1: Tokenize sentences\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "# Step 2: Create frequency matrix for each sentence\n",
        "word_frequencies = []\n",
        "for sentence in sentences:\n",
        "    words = word_tokenize(sentence.lower())\n",
        "    words = [word for word in words if word.isalnum()]  # Remove non-alphanumeric characters\n",
        "    word_freq = Counter(words)\n",
        "    word_frequencies.append(word_freq)\n",
        "\n",
        "# Step 3: Calculate Term Frequency (TF) for each sentence\n",
        "# TF = frequency of word in sentence / total words in sentence\n",
        "tf_matrix = []\n",
        "for word_freq in word_frequencies:\n",
        "    total_words_in_sentence = sum(word_freq.values())\n",
        "    tf_sentence = {word: freq / total_words_in_sentence for word, freq in word_freq.items()}\n",
        "    tf_matrix.append(tf_sentence)\n",
        "\n",
        "# Step 4: Create a table for documents per word\n",
        "# Document per word counts how many sentences contain the word\n",
        "word_document_count = {}\n",
        "for word_freq in word_frequencies:\n",
        "    for word in word_freq:\n",
        "        word_document_count[word] = word_document_count.get(word, 0) + 1\n",
        "\n",
        "# Step 5: Calculate Inverse Document Frequency (IDF)\n",
        "# IDF = log(total number of sentences / number of sentences containing the word)\n",
        "total_sentences = len(sentences)\n",
        "idf = {}\n",
        "for word, doc_count in word_document_count.items():\n",
        "    idf[word] = math.log(total_sentences / doc_count)\n",
        "\n",
        "# Step 6: Calculate TF-IDF for each sentence\n",
        "# TF-IDF = TF * IDF\n",
        "tf_idf_matrix = []\n",
        "for tf_sentence in tf_matrix:\n",
        "    tf_idf_sentence = {word: tf_sentence.get(word, 0) * idf.get(word, 0) for word in tf_sentence}\n",
        "    tf_idf_matrix.append(tf_idf_sentence)\n",
        "\n",
        "# Step 7: Score each sentence based on the sum of TF-IDF scores\n",
        "sentence_scores = []\n",
        "for tf_idf_sentence in tf_idf_matrix:\n",
        "\n",
        "    sentence_score = sum(tf_idf_sentence.values())  # Sum of TF-IDF values in the sentence\n",
        "    sentence_scores.append(sentence_score)\n",
        "\n",
        "# Step 8: Find the threshold\n",
        "# Set the number of sentences you want in the summary (e.g., top 3 sentences)\n",
        "top_n = 3\n",
        "threshold_value = sorted(sentence_scores, reverse=True)[top_n-1]\n",
        "\n",
        "# Step 9: Generate the summary by selecting top sentences\n",
        "summary_sentences = []\n",
        "for idx, score in enumerate(sentence_scores):\n",
        "    if score >= threshold_value:\n",
        "        summary_sentences.append(sentences[idx])\n",
        "\n",
        "\n",
        "# Display input text\n",
        "print(\"Input Text:\")\n",
        "print(text)\n",
        "\n",
        "# Display the summary\n",
        "print(\"Summary:\")\n",
        "print(\" \".join(summary_sentences))\n",
        "\n",
        "\n"
      ]
    }
  ]
}